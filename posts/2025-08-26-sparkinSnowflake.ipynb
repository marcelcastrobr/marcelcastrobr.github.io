{
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "lastEditStatus": {
   "notebookId": "hyurclg4fy7evsin4xcv",
   "authorId": "1758781709217",
   "authorName": "MCASTRO",
   "authorEmail": "marcel.castro@snowflake.com",
   "sessionId": "0fdb589e-fd7c-48d1-8402-ed2f5a5ef1af",
   "lastEditTime": 1756239551186
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14bfc485-8fd7-4d16-a802-8ebd82bb56bf",
   "metadata": {
    "name": "cell1"
   },
   "source": [
    "---\n",
    "aliases:\n",
    "- /2025/08/26/SparkSnowflake\n",
    "badges: true\n",
    "categories:\n",
    "- spark\n",
    "- snowflake\n",
    "date: '2025-08-26'\n",
    "description: Details on how to run Apache Spark in Snowflake.\n",
    "output-file: 2025-08-26-sparkinSnowflake.html\n",
    "title: Running Apache Spark in Snowflake\n",
    "toc: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984a00a7-4030-497d-866b-a4e293881463",
   "metadata": {
    "collapsed": false,
    "name": "topic"
   },
   "source": "# Running Apache Spark in Snowflake\n\nDataset: https://health.data.ny.gov/api/views/jxy9-yhdk/rows.csv\n\n![image-20240507155528488](./images/image-sparksnowflake.png)\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0af9254-da40-4e5a-9525-8d3a34b379ea",
   "metadata": {
    "language": "python",
    "name": "setup"
   },
   "outputs": [],
   "source": "# Set up the env for Java libraries and enable the Spark Connect Mode\nimport os\nimport traceback\n\nos.environ['JAVA_HOME'] = os.environ[\"CONDA_PREFIX\"]\nos.environ['JAVA_LD_LIBRARY_PATH'] = os.path.join(os.environ[\"CONDA_PREFIX\"], 'lib', 'server')\nos.environ[\"SPARK_LOCAL_HOSTNAME\"] = \"127.0.0.1\"\nos.environ[\"SPARK_CONNECT_MODE_ENABLED\"] = \"1\"\n\nfrom snowflake import snowpark_connect\nfrom snowflake.snowpark.context import get_active_session\n\n\nsession = get_active_session()\nsnowpark_connect.start_session(snowpark_session = session)\n\n\n# Here is your normal pyspark code. You can of course have them in other Python Cells\nspark = snowpark_connect.get_session()\ndf = spark.sql(\"show schemas\").limit(10)\ndf.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc925d72-924d-4f3b-aca9-9fbdb0cf7b9f",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "create_dataframe"
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame with sample data using Snowpark\n",
    "from snowflake.snowpark.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "data = [[2021, \"test\", \"Albany\", \"M\", 42]]\n",
    "schema = StructType([\n",
    "    StructField(\"Year\", IntegerType()),\n",
    "    StructField(\"First_Name\", StringType()),\n",
    "    StructField(\"County\", StringType()),\n",
    "    StructField(\"Sex\", StringType()),\n",
    "    StructField(\"Count\", IntegerType())\n",
    "])\n",
    "\n",
    "df1 = session.create_dataframe(data, schema=schema)\n",
    "df1.show()  # Snowpark DataFrame show() method\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82578820-f654-411d-91e2-ca422fc610dd",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "load_csv"
   },
   "outputs": [],
   "source": [
    "# Read CSV file using Snowpark\n",
    "from snowflake.snowpark.types import *\n",
    "\n",
    "# Option 1: Read from stage using Snowpark\n",
    "df_csv = session.read.option(\"FIELD_DELIMITER\", \",\").option(\"SKIP_HEADER\", 1).csv(\"@aicollege.public.setup/row.csv\")\n",
    "\n",
    "# Option 2: If the CSV is already loaded as a table, use SQL\n",
    "# df_csv = session.table(\"your_table_name\")\n",
    "\n",
    "df_csv.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6d1b48-c43d-4074-b4c7-a31e6277d917",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "interact_with_dataframe"
   },
   "outputs": [],
   "source": [
    "# Print schema information for both DataFrames\n",
    "print(\"CSV DataFrame schema:\")\n",
    "df_csv.show(1)  # Show first row to see column structure\n",
    "print(\"\\nSample DataFrame schema:\")\n",
    "df1.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4972727b-6c8d-4f6d-969c-51e19a4a4bfa",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "rename"
   },
   "outputs": [],
   "source": [
    "# Rename column using Snowpark\n",
    "from snowflake.snowpark.functions import col\n",
    "\n",
    "df_csv = df_csv.with_column_renamed(\"First Name\", \"First_Name\")\n",
    "print(\"After renaming column:\")\n",
    "df_csv.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab83992-8170-490e-9632-3408d172d8a1",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "combine"
   },
   "outputs": [],
   "source": [
    "# Union DataFrames using Snowpark\n",
    "df = df1.union_all(df_csv)  # union_all is the Snowpark equivalent\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3644da-d810-4680-ad0d-b9d580bfa016",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "filter"
   },
   "outputs": [],
   "source": [
    "# Filter using Snowpark\n",
    "from snowflake.snowpark.functions import col\n",
    "\n",
    "df.filter(col(\"Count\") > 50).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fb7728-6dd4-4c5a-85cf-902903d82b9f",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "where"
   },
   "outputs": [],
   "source": [
    "df.where(df[\"Count\"] > 50).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974f5f38-bf7f-49ad-b7da-a4a98cc2c770",
   "metadata": {
    "language": "python",
    "name": "select_column"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "df.select(\"First_Name\", \"Count\").orderBy(desc(\"Count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0f848a-082b-4237-94ae-8209fd27abf6",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "subset_df"
   },
   "outputs": [],
   "source": [
    "subsetDF = df.filter((df[\"Year\"] == 2009) & (df[\"Count\"] > 100) & (df[\"Sex\"] == \"F\")).select(\"First_Name\", \"County\", \"Count\").orderBy(desc(\"Count\"))\n",
    "subsetDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88964d4a-e3a7-400e-ac7e-f1b5de990077",
   "metadata": {
    "language": "python",
    "name": "save_df"
   },
   "outputs": [],
   "source": [
    "df.write.mode(\"overwrite\").saveAsTable(\"AICOLLEGE.PUBLIC.MYFIRSTSPARK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98171cb6-6e9c-4adf-8248-bae1a4638068",
   "metadata": {
    "language": "python",
    "name": "save_to_json"
   },
   "outputs": [],
   "source": [
    "df.write.format(\"json\").mode(\"overwrite\").save(f\"@aicollege.public.setup/myfirstspark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10945fd0-e03e-4f4e-a172-5b62055c6e74",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "read_json"
   },
   "outputs": [],
   "source": [
    "#spark.read.format(\"json\").json(f\"@aicollege.public.setup/myfirstspark\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bac19c-6ab6-40e7-bbb7-b46cbab0d2c8",
   "metadata": {
    "language": "python",
    "name": "selectExpr"
   },
   "outputs": [],
   "source": [
    "df.selectExpr(\"Count\", \"upper(County) as big_name\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7565d0-1708-4f33-918f-f6d2669e359b",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "expr"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "df.select(\"Count\", expr(\"lower(County) as little_name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4af7cf4-4023-42b0-acb9-4cd11189c80e",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "spark_sql"
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"SELECT * FROM AICOLLEGE.PUBLIC.MYFIRSTSPARK\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72ab187-598b-4f32-9456-b819c315ab51",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": []
  }
 ]
}