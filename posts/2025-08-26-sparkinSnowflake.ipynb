{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67313b5e",
   "metadata": {},
   "source": [
    "---\n",
    "aliases:\n",
    "- /2025/08/26/SparkSnowflake\n",
    "date: '2025-08-26'\n",
    "output-file: 2025-08-26-sparkinSnowflake.html\n",
    "title: Running Apache Spark in Snowflake\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984a00a7-4030-497d-866b-a4e293881463",
   "metadata": {
    "collapsed": false,
    "name": "topic"
   },
   "source": [
    "# Running Apache Spark in Snowflake\n",
    "\n",
    "Dataset: https://health.data.ny.gov/api/views/jxy9-yhdk/rows.csv\n",
    "\n",
    "![image-20240507155528488](./images/image-sparksnowflake.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0af9254-da40-4e5a-9525-8d3a34b379ea",
   "metadata": {
    "language": "python",
    "name": "setup"
   },
   "outputs": [],
   "source": [
    "# Set up the env for Java libraries and enable the Spark Connect Mode\n",
    "import os\n",
    "import traceback\n",
    "\n",
    "os.environ['JAVA_HOME'] = os.environ[\"CONDA_PREFIX\"]\n",
    "os.environ['JAVA_LD_LIBRARY_PATH'] = os.path.join(os.environ[\"CONDA_PREFIX\"], 'lib', 'server')\n",
    "os.environ[\"SPARK_LOCAL_HOSTNAME\"] = \"127.0.0.1\"\n",
    "os.environ[\"SPARK_CONNECT_MODE_ENABLED\"] = \"1\"\n",
    "\n",
    "from snowflake import snowpark_connect\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "\n",
    "\n",
    "session = get_active_session()\n",
    "snowpark_connect.start_session(snowpark_session = session)\n",
    "\n",
    "# Here is your normal pyspark code. You can of course have them in other Python Cells\n",
    "spark = snowpark_connect.get_session()\n",
    "df = spark.sql(\"show schemas\").limit(10)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc925d72-924d-4f3b-aca9-9fbdb0cf7b9f",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "create_dataframe"
   },
   "outputs": [],
   "source": [
    "data = [[2021, \"test\", \"Albany\", \"M\", 42]]\n",
    "columns = [\"Year\", \"First_Name\", \"County\", \"Sex\", \"Count\"]\n",
    "\n",
    "df1 = spark.createDataFrame(data, schema=\"Year int, First_Name STRING, County STRING, Sex STRING, Count int\")\n",
    "#display(df1) # The display() method is specific to Databricks notebooks and provides a richer visualization.\n",
    "df1.show() #The show() method is a part of the Apache Spark DataFrame API and provides basic visualization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82578820-f654-411d-91e2-ca422fc610dd",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "load_csv"
   },
   "outputs": [],
   "source": [
    "df_csv = spark.read.csv(f\"@aicollege.public.setup/row.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    "    sep=\",\")\n",
    "#display(df_csv)\n",
    "df_csv.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6d1b48-c43d-4074-b4c7-a31e6277d917",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "interact_with_dataframe"
   },
   "outputs": [],
   "source": [
    "df_csv.printSchema()\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4972727b-6c8d-4f6d-969c-51e19a4a4bfa",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "rename"
   },
   "outputs": [],
   "source": [
    "df_csv = df_csv.withColumnRenamed(\"First Name\", \"First_Name\")\n",
    "df_csv.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab83992-8170-490e-9632-3408d172d8a1",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "combine"
   },
   "outputs": [],
   "source": [
    "df = df1.union(df_csv)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3644da-d810-4680-ad0d-b9d580bfa016",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "filter"
   },
   "outputs": [],
   "source": [
    "df.filter(df[\"Count\"] > 50).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fb7728-6dd4-4c5a-85cf-902903d82b9f",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "where"
   },
   "outputs": [],
   "source": [
    "df.where(df[\"Count\"] > 50).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974f5f38-bf7f-49ad-b7da-a4a98cc2c770",
   "metadata": {
    "language": "python",
    "name": "select_column"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "df.select(\"First_Name\", \"Count\").orderBy(desc(\"Count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0f848a-082b-4237-94ae-8209fd27abf6",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "subset_df"
   },
   "outputs": [],
   "source": [
    "subsetDF = df.filter((df[\"Year\"] == 2009) & (df[\"Count\"] > 100) & (df[\"Sex\"] == \"F\")).select(\"First_Name\", \"County\", \"Count\").orderBy(desc(\"Count\"))\n",
    "subsetDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88964d4a-e3a7-400e-ac7e-f1b5de990077",
   "metadata": {
    "language": "python",
    "name": "save_df"
   },
   "outputs": [],
   "source": [
    "df.write.mode(\"overwrite\").saveAsTable(\"AICOLLEGE.PUBLIC.MYFIRSTSPARK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98171cb6-6e9c-4adf-8248-bae1a4638068",
   "metadata": {
    "language": "python",
    "name": "save_to_json"
   },
   "outputs": [],
   "source": [
    "df.write.format(\"json\").mode(\"overwrite\").save(f\"@aicollege.public.setup/myfirstspark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10945fd0-e03e-4f4e-a172-5b62055c6e74",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "read_json"
   },
   "outputs": [],
   "source": [
    "#spark.read.format(\"json\").json(f\"@aicollege.public.setup/myfirstspark\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bac19c-6ab6-40e7-bbb7-b46cbab0d2c8",
   "metadata": {
    "language": "python",
    "name": "selectExpr"
   },
   "outputs": [],
   "source": [
    "df.selectExpr(\"Count\", \"upper(County) as big_name\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7565d0-1708-4f33-918f-f6d2669e359b",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "expr"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "df.select(\"Count\", expr(\"lower(County) as little_name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4af7cf4-4023-42b0-acb9-4cd11189c80e",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "spark_sql"
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"SELECT * FROM AICOLLEGE.PUBLIC.MYFIRSTSPARK\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72ab187-598b-4f32-9456-b819c315ab51",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "marcel.castro@snowflake.com",
   "authorId": "1758781709217",
   "authorName": "MCASTRO",
   "lastEditTime": 1756201624346,
   "notebookId": "e7vo3spfdekqllwwex7r",
   "sessionId": "88935d78-b90d-4bf4-b8f2-59d76b2af6ce"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
