<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2024-03-11">

<title>Train Falcon with near-linear scaling using Sharded Data Parallelism technique in SageMaker Model Parallelism Library – Marcel Castro</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-e8eb0a5f0817fce1bde8f0144c0d4cbd.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-RK1QNXR9TB"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-RK1QNXR9TB', { 'anonymize_ip': true});
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed fullcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Marcel Castro</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://marcelcastrobr.github.io/my_ml_notes/"> 
<span class="menu-text">Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Notebooks</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://marcelcastrobr.github.io/my_ml_links/"> 
<span class="menu-text">Links</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/marcelcastrobr/marcelcastrobr.github.io/blob/main/cv/cv-marcelcastro.pdf"> <i class="bi bi-filetype-pdf" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://marcelcastrobr.github.io/my_ml_links/"> <i class="bi bi-diagram-3-fill" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://huggingface.co/marcelcastrobr"> <i class="bi bi-emoji-smile" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/marcelcastrobr"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/marcelcastrobr/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Train Falcon with near-linear scaling using Sharded Data Parallelism technique in SageMaker Model Parallelism Library</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">March 11, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="train-falcon-with-near-linear-scaling-using-sharded-data-parallelism-technique-in-sagemaker-model-parallelism-library" class="level1">
<h1>Train Falcon with near-linear scaling using Sharded Data Parallelism technique in SageMaker Model Parallelism Library</h1>
<hr>
<p>This notebook’s CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-2/training%7Cdistributed_training%7Cpytorch%7Cmodel_parallel%7Cgpt2%7Csmp-train-gpt-simple-sharded-data-parallel.ipynb" class="img-fluid figure-img"></p>
<figcaption>This badge failed to load. Check your device’s internet connectivity, otherwise the service is currently unavailable</figcaption>
</figure>
</div>
<hr>
<p>In this notebook, you’ll learn how to train the Hugging Face Transformers <a href="https://huggingface.co/docs/transformers/main/model_doc/falcon">Falcon</a> model with the <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-parallel-extended-features-pytorch-sharded-data-parallelism.html">Sharded Data Parallelism</a> technique supported by <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-parallel.html">SageMaker’s Model Parallelism library (SMP)</a> with PyTorch 2.0 and <a href="https://huggingface.co/datasets/glue/viewer/sst2/train">GLUE/SST2 dataset</a> on SageMaker.</p>
<p>Sharded data parallelism is a distributed training technique that splits the model parameters, gradients, and optimizer states across GPUs in a data parallel group. It is purpose-built for extreme-scale models and leverages Amazon in-house <a href="https://arxiv.org/pdf/2205.00119.pdf">MiCS</a> technology which achieves a near-linear scaling efficiency. For large models that cannot fit into a single GPU, we also recommend using the sharded data parallelism technique with <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-parallel-extended-features-pytorch-activation-checkpointing.html">Activation Checkpointing</a> and <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-parallel-extended-features-pytorch-activation-offloading.html">Activation Offloading</a> in SMP first, before leveraging other techniques such as tensor parallelism or pipeline parallelism.</p>
<p>This feature is also compatible with <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-parallel-extended-features-pytorch-tensor-parallelism.html">Tensor Parallelism</a>.</p>
<p>This notebook is accompanied by the following files:</p>
<ul>
<li><code>train.py</code>: The entry point script that’ll be passed to the SageMaker PyTorch estimator later in this notebook when launching the training job. This script is prepared to run an end-to-end training of the Falcon model with SMP, settings for sharded data parallelism applied, and implemented with code lines to save, load, and fine-tune the model. You can follow the comments throughout the script to learn where the SMP APIs and code modifications are implemented.</li>
<li><code>data_pipeline.py</code>: This has data pipeline functions to prepare the training dataset.</li>
<li><code>learining_rate.py</code>: This has functions for learning rate schedule.</li>
<li><code>requirements.txt</code>: This installs the dependencies, including huggingface transformers.</li>
<li><code>memory_tracker.py</code>: This has functions to track memory usage.</li>
<li><code>model_config.py</code>: This has functions to get model configuration information.</li>
<li><code>sdp_utils.py</code>: This has util functions for sharded data parallelism.</li>
</ul>
<section id="additional-resources" class="level3">
<h3 class="anchored" data-anchor-id="additional-resources">Additional resources</h3>
<ul>
<li><p>To learn more about the SageMaker model parallelism library, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-parallel.html">Model Parallel Distributed Training with SageMaker Distributed</a>.</p></li>
<li><p>To learn more about using the SageMaker Python SDK with PyTorch, see <a href="https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html">Using PyTorch with the SageMaker Python SDK</a>.</p></li>
<li><p>To learn more about launching a training job in Amazon SageMaker with your own training image, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo.html">Use Your Own Training Algorithms</a>.</p></li>
<li><p>To learn more about sharded data parallelism, check <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-parallel-extended-features-pytorch-sharded-data-parallelism.html">Sharded Data Parallelism</a> or the blog <a href="https://www.amazon.science/blog/near-linear-scaling-of-gigantic-model-training-on-aws">Near-linear scaling of gigantic-model training on AWS</a>.</p></li>
</ul>
</section>
<section id="prerequisites" class="level3">
<h3 class="anchored" data-anchor-id="prerequisites">Prerequisites</h3>
<p>You must create an S3 bucket to store the input data for training. This bucket must be located in the same AWS Region that you choose to launch your training job. To learn how to create a S3 bucket, see <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/creating-bucket.html">Create your first S3 bucket</a> in the <em>Amazon S3 documentation</em>.</p>
</section>
<section id="amazon-sagemaker-initialization" class="level2">
<h2 class="anchored" data-anchor-id="amazon-sagemaker-initialization">Amazon SageMaker initialization</h2>
<p>Run the following cell to import SageMaker modules and retrieve information of your current SageMaker work environment, such as your AWS account ID, the AWS Region, and the ARN of your Amazon SageMaker execution role. Upgrade SageMaker SDK to the latest version.</p>
<p><strong>NOTE:</strong> This step might require a kernel restart.</p>
<div id="cell-5" class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install <span class="op">--</span>upgrade sagemaker</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install sagemaker<span class="op">-</span>experiments</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-6" class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>time</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> boto3</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sagemaker</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sagemaker <span class="im">import</span> get_execution_role</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sagemaker.pytorch <span class="im">import</span> PyTorch</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>role <span class="op">=</span> (</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    get_execution_role()</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>)  <span class="co"># provide a pre-existing role ARN as an alternative to creating a new role</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"SageMaker Execution Role: </span><span class="sc">{</span>role<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>client <span class="op">=</span> boto3.client(<span class="st">"sts"</span>)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>account <span class="op">=</span> client.get_caller_identity()[<span class="st">"Account"</span>]</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"AWS account: </span><span class="sc">{</span>account<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>session <span class="op">=</span> boto3.session.Session()</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>region <span class="op">=</span> session.region_name</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"AWS region: </span><span class="sc">{</span>region<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>sm_boto_client <span class="op">=</span> boto3.client(<span class="st">"sagemaker"</span>)</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>sagemaker_session <span class="op">=</span> sagemaker.session.Session(boto_session<span class="op">=</span>session)</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a><span class="co"># get default bucket</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>default_bucket <span class="op">=</span> sagemaker_session.default_bucket()</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Default bucket for this session: "</span>, default_bucket)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="download-and-prepare-gluesst2-data" class="level2">
<h2 class="anchored" data-anchor-id="download-and-prepare-gluesst2-data">Download and prepare GLUE/SST2 data</h2>
<p>Here you will download, prepare the GLUE/SST2 dataset and then copy the files to S3.</p>
<section id="install-the-hugging-face-transformers-and-datasets-libraries" class="level3">
<h3 class="anchored" data-anchor-id="install-the-hugging-face-transformers-and-datasets-libraries">Install the Hugging Face Transformers and Datasets libraries</h3>
<div id="cell-9" class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> pip install <span class="op">-</span>q datasets transformers<span class="op">==</span><span class="fl">4.21.0</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-10" class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> datasets</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset, load_from_disk, load_metric</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-11" class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sagemaker.pytorch <span class="im">import</span> PyTorch</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> transformers</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> logging</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> (</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    AutoModelForCausalLM,</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    AutoTokenizer,</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers.testing_utils <span class="im">import</span> CaptureLogger</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-12" class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>logger <span class="op">=</span> logging.getLogger(<span class="va">__name__</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="load-data" class="level3">
<h3 class="anchored" data-anchor-id="load-data">Load data</h3>
<p>This section loads the <a href="https://huggingface.co/datasets/glue/viewer/sst2/train">GLUE/SST2</a> dataset and splits it to training and validation datasets.</p>
<div id="cell-14" class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>hyperparameters <span class="op">=</span> {</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"dataset_name"</span>: <span class="st">"glue"</span>,</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"dataset_config_name"</span>: <span class="st">"sst2"</span>,</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"do_train"</span>: <span class="va">True</span>,</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"do_eval"</span>: <span class="va">True</span>,</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"cache_dir"</span>: <span class="st">"tmp"</span>,</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-15" class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>raw_datasets <span class="op">=</span> load_dataset(</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    hyperparameters[<span class="st">"dataset_name"</span>],</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    hyperparameters[<span class="st">"dataset_config_name"</span>],</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-16" class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">"validation"</span> <span class="kw">not</span> <span class="kw">in</span> raw_datasets.keys():</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    raw_datasets[<span class="st">"validation"</span>] <span class="op">=</span> load_dataset(</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>        hyperparameters[<span class="st">"dataset_name"</span>],</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>        hyperparameters[<span class="st">"dataset_config_name"</span>],</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>        split<span class="op">=</span><span class="st">"train[:5%]"</span>,</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>        cache_dir<span class="op">=</span>hyperparameters[<span class="st">"cache_dir"</span>],</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    raw_datasets[<span class="st">"train"</span>] <span class="op">=</span> load_dataset(</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>        hyperparameters[<span class="st">"dataset_name"</span>],</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>        hyperparameters[<span class="st">"dataset_config_name"</span>],</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>        split<span class="op">=</span><span class="st">"train[5%:]"</span>,</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>        cache_dir<span class="op">=</span>hyperparameters[<span class="st">"cache_dir"</span>],</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="load-tokenizer" class="level3">
<h3 class="anchored" data-anchor-id="load-tokenizer">Load tokenizer</h3>
<p>Nearly every NLP task begins with a tokenizer. A tokenizer converts your text data into a format (token) that can be processed by the NLP model. The following cell loads a tokenizer for Falcon using <a href="https://huggingface.co/docs/transformers/v4.19.4/en/autoclass_tutorial#autotokenizer">AutoTokenizer.from_pretrained()</a>.</p>
<div id="cell-18" class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>tokenizer_kwargs <span class="op">=</span> {</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"cache_dir"</span>: hyperparameters[<span class="st">"cache_dir"</span>],</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"tiiuae/falcon-40b"</span>, trust_remote_code<span class="op">=</span><span class="va">True</span>, <span class="op">**</span>tokenizer_kwargs</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="preprocess-data" class="level3">
<h3 class="anchored" data-anchor-id="preprocess-data">Preprocess data</h3>
<p>The following two cells set up a function to run the tokenizer and group texts into chunks smaller than the block size.</p>
<div id="cell-20" class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tokenize_function(examples):</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    tok_logger <span class="op">=</span> transformers.utils.logging.get_logger(<span class="st">"transformers.tokenization_utils_base"</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> CaptureLogger(tok_logger) <span class="im">as</span> cl:</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> tokenizer(examples[text_column_name])</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># clm input could be much much longer than block_size</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">"Token indices sequence length is longer than the"</span> <span class="kw">in</span> cl.out:</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>            tok_logger.warning(</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>                <span class="st">"^^^^^^^^^^^^^^^^ Please ignore the warning above - this long input will be chunked into smaller bits before being passed to the model."</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> output</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Main data processing function that will concatenate all texts from our dataset and generate chunks of block_size.</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> group_texts(examples):</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Concatenate all texts.</span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>    concatenated_examples <span class="op">=</span> {k: <span class="bu">sum</span>(examples[k], []) <span class="cf">for</span> k <span class="kw">in</span> examples.keys()}</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>    total_length <span class="op">=</span> <span class="bu">len</span>(concatenated_examples[<span class="bu">list</span>(examples.keys())[<span class="dv">0</span>]])</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We drop the small remainder, we could add padding if the model supported it instead of this drop, you can</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># customize this part to your needs.</span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> total_length <span class="op">&gt;=</span> block_size:</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>        total_length <span class="op">=</span> (total_length <span class="op">//</span> block_size) <span class="op">*</span> block_size</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Split by chunks of max_len.</span></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> {</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>            k: [t[i : i <span class="op">+</span> block_size] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, total_length, block_size)]</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> k, t <span class="kw">in</span> concatenated_examples.items()</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>    result[<span class="st">"labels"</span>] <span class="op">=</span> result[<span class="st">"input_ids"</span>].copy()</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-21" class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>column_names <span class="op">=</span> raw_datasets[<span class="st">"train"</span>].column_names</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>text_column_name <span class="op">=</span> <span class="st">"text"</span> <span class="cf">if</span> <span class="st">"text"</span> <span class="kw">in</span> column_names <span class="cf">else</span> column_names[<span class="dv">0</span>]</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co"># since this will be pickled to avoid _LazyModule error in Hasher force logger loading before tokenize_function</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>tok_logger <span class="op">=</span> transformers.utils.logging.get_logger(<span class="st">"transformers.tokenization_utils_base"</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>tokenized_datasets <span class="op">=</span> raw_datasets.<span class="bu">map</span>(</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    tokenize_function,</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    batched<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    num_proc<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    remove_columns<span class="op">=</span>column_names,</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    desc<span class="op">=</span><span class="st">"Running tokenizer on dataset"</span>,</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>block_size <span class="op">=</span> tokenizer.model_max_length</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> block_size <span class="op">&gt;</span> <span class="dv">1024</span>:</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>    logger.warning(</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"The tokenizer picked seems to have a very large `model_max_length` (</span><span class="sc">{</span>tokenizer<span class="sc">.</span>model_max_length<span class="sc">}</span><span class="ss">). "</span></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Picking 1024 instead. You can change that default value by passing --block_size xxx."</span></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>    block_size <span class="op">=</span> <span class="dv">1024</span></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> block_size <span class="op">&gt;</span> tokenizer.model_max_length:</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>        logger.warning(</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"The block_size passed (</span><span class="sc">{</span>block_size<span class="sc">}</span><span class="ss">) is larger than the maximum length for the model"</span></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"(</span><span class="sc">{</span>tokenizer<span class="sc">.</span>model_max_length<span class="sc">}</span><span class="ss">). Using block_size=</span><span class="sc">{</span>tokenizer<span class="sc">.</span>model_max_length<span class="sc">}</span><span class="ss">."</span></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>    block_size <span class="op">=</span> <span class="bu">min</span>(block_size, tokenizer.model_max_length)</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>lm_datasets <span class="op">=</span> tokenized_datasets.<span class="bu">map</span>(</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>    group_texts,</span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>    batched<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     num_proc=args.preprocessing_num_workers,</span></span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>    desc<span class="op">=</span><span class="ss">f"Grouping texts in chunks of </span><span class="sc">{</span>block_size<span class="sc">}</span><span class="ss">"</span>,</span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Set additional hyperparameters and S3 paths for mapping the train and validation datasets properly depending on the phase (training or validation) of the training job in each epoch.</p>
<div id="cell-23" class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> hyperparameters[<span class="st">"do_train"</span>]:</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">"train"</span> <span class="kw">not</span> <span class="kw">in</span> tokenized_datasets:</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"--do_train requires a train dataset"</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    train_dataset <span class="op">=</span> lm_datasets[<span class="st">"train"</span>]</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> hyperparameters[<span class="st">"do_eval"</span>]:</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">"validation"</span> <span class="kw">not</span> <span class="kw">in</span> tokenized_datasets:</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"--do_eval requires a validation dataset"</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    eval_dataset <span class="op">=</span> lm_datasets[<span class="st">"validation"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-24" class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>training_dataset_location <span class="op">=</span> <span class="va">None</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>validation_dataset_location <span class="op">=</span> <span class="va">None</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> hyperparameters[<span class="st">"do_train"</span>]:</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    train_dataset.to_json(<span class="st">"./training.json"</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    training_dataset_location <span class="op">=</span> <span class="st">"s3://</span><span class="sc">{}</span><span class="st">/dataset/train/"</span>.<span class="bu">format</span>(default_bucket)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> hyperparameters[<span class="st">"do_eval"</span>]:</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    eval_dataset.to_json(<span class="st">"./validation.json"</span>)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>    validation_dataset_location <span class="op">=</span> <span class="st">"s3://</span><span class="sc">{}</span><span class="st">/dataset/validation/"</span>.<span class="bu">format</span>(default_bucket)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-25" class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> training_dataset_location <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    command <span class="op">=</span> <span class="st">"aws s3 cp ./training.json </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(training_dataset_location)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    os.system(command)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> validation_dataset_location <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    command <span class="op">=</span> <span class="st">"aws s3 cp ./validation.json </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(validation_dataset_location)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    os.system(command)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-26" class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> hyperparameters[<span class="st">"do_train"</span>]:</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    command <span class="op">=</span> <span class="st">"rm ./training.json"</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    os.system(command)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> hyperparameters[<span class="st">"do_eval"</span>]:</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    command <span class="op">=</span> <span class="st">"rm ./validation.json"</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    os.system(command)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-27" class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>store training_dataset_location</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>store validation_dataset_location</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-28" class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>store</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="specify-amazon-s3-bucket-paths" class="level2">
<h2 class="anchored" data-anchor-id="specify-amazon-s3-bucket-paths">Specify Amazon S3 bucket paths</h2>
<p>Here you need to specify the paths for training data to be used by your job. The bucket used must be in the same region as where training will run. In the cells above you downloaded the GLUE/SST2 training and validation split datasets and uploaded the json files in an S3 bucket in your account. This example will train on those json files.</p>
<p>After you successfully run this example tensor parallel training job, you can modify the S3 bucket to where your own dataset is stored.</p>
<div id="cell-31" class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>store <span class="op">-</span>r training_dataset_location</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>store <span class="op">-</span>r validation_dataset_location</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="co"># if you're bringing your own data, uncomment the following lines and specify the locations there</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co"># training_dataset_location = YOUR_S3_BUCKET/training</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="co"># validation_dataset_location = YOUR_S3_BUCKET/validation</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-32" class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>s3_train_bucket <span class="op">=</span> training_dataset_location</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>s3_test_bucket <span class="op">=</span> validation_dataset_location</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The following S3 bucket will store the output artifacts of the training job. You can modify this as needed.</p>
<div id="cell-34" class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>s3_output_bucket <span class="op">=</span> <span class="ss">f"s3://sagemaker-</span><span class="sc">{</span>region<span class="sc">}</span><span class="ss">-</span><span class="sc">{</span>account<span class="sc">}</span><span class="ss">/smp-tensorparallel-outputdir/"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="define-data-channels-for-sagemaker-training-using-amazon-s3" class="level2">
<h2 class="anchored" data-anchor-id="define-data-channels-for-sagemaker-training-using-amazon-s3">Define data channels for SageMaker Training using Amazon S3</h2>
<p>In this step, define SageMaker training data channels to the S3 buckets.</p>
<div id="cell-36" class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set use_fsx to False by default</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Set below var to True if you want to use fsx (see next cell)</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>use_fsx <span class="op">=</span> <span class="va">False</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> use_fsx:</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> s3_train_bucket <span class="op">!=</span> <span class="va">None</span>:</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>        train <span class="op">=</span> sagemaker.inputs.TrainingInput(</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>            s3_train_bucket, distribution<span class="op">=</span><span class="st">"FullyReplicated"</span>, s3_data_type<span class="op">=</span><span class="st">"S3Prefix"</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>        data_channels <span class="op">=</span> {<span class="st">"train"</span>: train}</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>        data_channels <span class="op">=</span> {<span class="st">"train"</span>: mock_data}</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> s3_test_bucket <span class="op">!=</span> <span class="va">None</span>:</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>        test <span class="op">=</span> sagemaker.inputs.TrainingInput(</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>            s3_test_bucket, distribution<span class="op">=</span><span class="st">"FullyReplicated"</span>, s3_data_type<span class="op">=</span><span class="st">"S3Prefix"</span></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>        data_channels[<span class="st">"test"</span>] <span class="op">=</span> test</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>        data_channels[<span class="st">"test"</span>] <span class="op">=</span> mock_data</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(data_channels)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="optional-set-up-and-use-amazon-fsx-for-data-channels-and-checkpoints" class="level2">
<h2 class="anchored" data-anchor-id="optional-set-up-and-use-amazon-fsx-for-data-channels-and-checkpoints">(Optional) Set up and use Amazon FSx for data channels and checkpoints</h2>
<p>While the previous option of using Amazon S3 is easier to set up, using an FSx can be beneficial for performance when dealing with large input sizes and large model sizes. If you are using models above 13B, checkpointing should be done using FSx.</p>
<p>Please see the instructions from <a href="https://github.com/aws/amazon-sagemaker-examples/blob/master/advanced_functionality/distributed_tensorflow_mask_rcnn/mask-rcnn-scriptmode-fsx.ipynb">Distributed Training of Mask-RCNN in Amazon SageMaker Using FSx</a> to create an FSx Lustre file system and import the dataset from the S3 bucket to your FSx file system. Note that the FSx file system must be created in a private subnet with internet gateway to ensure that training job has access to the internet. For general guidance on setting an FSx Lustre file system as data input channel, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-access-training-data.html#model-access-training-data-fsx">Configure Data Input Channel to Use Amazon FSx for Lustre</a>.</p>
<div id="cell-38" class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Instructions obtained from:</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co"># https://github.com/aws/amazon-sagemaker-examples/blob/master/advanced_functionality/distributed_tensorflow_mask_rcnn/mask-rcnn-scriptmode-fsx.ipynb</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> use_fsx:</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>    <span class="im">from</span> sagemaker.inputs <span class="im">import</span> FileSystemInput</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Specify FSx Lustre file system id.</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>    file_system_id <span class="op">=</span> <span class="st">"&lt;your-file-system-id&gt;"</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Specify the SG and subnet used by the FSX, these are passed to SM Estimator so jobs use this as well</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>    fsx_security_group_id <span class="op">=</span> <span class="st">"&lt;your-security-group-id&gt;"</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>    fsx_subnet <span class="op">=</span> <span class="st">"&lt;your-subnet&gt;"</span></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Specify directory path for input data on the file system.</span></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># You need to provide normalized and absolute path below.</span></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Your mount name can be provided by you when creating fsx, or generated automatically.</span></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># You can find this mount_name on the FSX page in console.</span></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Example of fsx generated mount_name: "3x5lhbmv"</span></span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>    base_path <span class="op">=</span> <span class="st">"&lt;your-mount-name&gt;"</span></span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Specify your file system type.</span></span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>    file_system_type <span class="op">=</span> <span class="st">"FSxLustre"</span></span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>    train <span class="op">=</span> FileSystemInput(</span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>        file_system_id<span class="op">=</span>file_system_id,</span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a>        file_system_type<span class="op">=</span>file_system_type,</span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a>        directory_path<span class="op">=</span>base_path,</span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a>        file_system_access_mode<span class="op">=</span><span class="st">"rw"</span>,</span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a>    data_channels <span class="op">=</span> {<span class="st">"train"</span>: train, <span class="st">"test"</span>: train}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="set-hyperparameters-metric-definitions-and-mpi-options" class="level2">
<h2 class="anchored" data-anchor-id="set-hyperparameters-metric-definitions-and-mpi-options">Set hyperparameters, metric definitions, and MPI options</h2>
<p>The following <code>hyperparameters</code> dictionary passes arguments to the training script (<code>train.py</code>) and set the model parallel configuration when creating the training job.</p>
<p>You can also add custom <code>mpi</code> flags. By default, we have <code>--mca btl_vader_single_copy_mechanism none</code> to remove unnecessary logs.</p>
<p>Next, we add a base metric definitions to enable the metric upload in SageMaker. You can add any further metric definitions.</p>
<p>Note that we add the <code>sharded_data_parallel_degree</code> parameter to the <code>hyperparameter</code> dictionary. This will be parsed and used when we configure a SageMaker PyTorch estimator to activate sharded data parallelism.</p>
<div id="cell-40" class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>hyperparameters <span class="op">=</span> {</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"max_steps"</span>: <span class="dv">100</span>,</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"seed"</span>: <span class="dv">12345</span>,</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"fp16"</span>: <span class="dv">0</span>,</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"bf16"</span>: <span class="dv">1</span>,</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"lr"</span>: <span class="fl">2.0e-4</span>,</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"lr_decay_iters"</span>: <span class="dv">125000</span>,</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"min_lr"</span>: <span class="fl">0.00001</span>,</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">"lr-decay-style"</span>: <span class="st">"linear"</span>,</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">"warmup"</span>: <span class="fl">0.01</span>,</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">"num_kept_checkpoints"</span>: <span class="dv">5</span>,</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">"checkpoint_freq"</span>: <span class="dv">200</span>,</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">"logging_freq"</span>: <span class="dv">1</span>,</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">"save_final_full_model"</span>: <span class="dv">0</span>,</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">"delayed_param"</span>: <span class="dv">1</span>,</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">"offload_activations"</span>: <span class="dv">0</span>,</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">"activation_loading_horizon"</span>: <span class="dv">4</span>,</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">"gradient_accumulation"</span>: <span class="dv">1</span>,</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">"validation_freq"</span>: <span class="dv">200</span>,</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>    <span class="st">"train_batch_size"</span>: <span class="dv">4</span>,</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>    <span class="st">"val_batch_size"</span>: <span class="dv">4</span>,</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>    <span class="st">"zipped_data"</span>: <span class="dv">0</span>,</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">"epochs"</span>: <span class="dv">100</span>,</span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">"use_distributed_transformer"</span>: <span class="dv">0</span>,</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">"model_type"</span>: <span class="st">"falcon"</span>,</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># parameters for sharded data parallelism</span></span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>    <span class="st">"sharded_data_parallel_degree"</span>: <span class="dv">16</span>,</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> use_fsx:</span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># make sure to update paths for training-dir and test-dir based on the paths of datasets in fsx</span></span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># If you want to resume training, set checkpoint-dir to the same path as a previous job.</span></span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a>    SM_TRAIN_DIR <span class="op">=</span> <span class="st">"/opt/ml/input/data/train"</span></span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a>    hyperparameters[<span class="st">"checkpoint-dir"</span>] <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>SM_TRAIN_DIR<span class="sc">}</span><span class="ss">/checkpointdir-job2"</span></span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a>    hyperparameters[<span class="st">"model-dir"</span>] <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>SM_TRAIN_DIR<span class="sc">}</span><span class="ss">/modeldir-job2"</span></span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>    hyperparameters[<span class="st">"training-dir"</span>] <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>SM_TRAIN_DIR<span class="sc">}</span><span class="ss">/datasets/pytorch_gpt/train_synthetic"</span></span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a>    hyperparameters[<span class="st">"test-dir"</span>] <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>SM_TRAIN_DIR<span class="sc">}</span><span class="ss">/datasets/pytorch_gpt/val_synthetic"</span></span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a><span class="co"># The checkpoint path (hyperparameters['checkpoint-dir'] or checkpoint_s3_uri) is not unique per job.</span></span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a><span class="co"># You need to modify as needed for different runs.</span></span>
<span id="cb24-41"><a href="#cb24-41" aria-hidden="true" tabindex="-1"></a><span class="co"># If same path is used for unrelated runs, this may increase time when downloading unnecessary checkpoints,</span></span>
<span id="cb24-42"><a href="#cb24-42" aria-hidden="true" tabindex="-1"></a><span class="co"># and cause conflicts when loading checkpoints.</span></span>
<span id="cb24-43"><a href="#cb24-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-44"><a href="#cb24-44" aria-hidden="true" tabindex="-1"></a>mpioptions <span class="op">=</span> <span class="st">"-x NCCL_DEBUG=WARN -x SMDEBUG_LOG_LEVEL=ERROR "</span></span>
<span id="cb24-45"><a href="#cb24-45" aria-hidden="true" tabindex="-1"></a>mpioptions <span class="op">+=</span> (</span>
<span id="cb24-46"><a href="#cb24-46" aria-hidden="true" tabindex="-1"></a>    <span class="st">"-x SMP_DISABLE_D2D=1 -x SMP_D2D_GPU_BUFFER_SIZE_BYTES=1 -x SMP_NCCL_THROTTLE_LIMIT=1 "</span></span>
<span id="cb24-47"><a href="#cb24-47" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb24-48"><a href="#cb24-48" aria-hidden="true" tabindex="-1"></a>mpioptions <span class="op">+=</span> <span class="st">"-x FI_EFA_USE_DEVICE_RDMA=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1"</span></span>
<span id="cb24-49"><a href="#cb24-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-50"><a href="#cb24-50" aria-hidden="true" tabindex="-1"></a>metric_definitions <span class="op">=</span> [</span>
<span id="cb24-51"><a href="#cb24-51" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"Name"</span>: <span class="st">"base_metric"</span>, <span class="st">"Regex"</span>: <span class="st">"&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;"</span>}</span>
<span id="cb24-52"><a href="#cb24-52" aria-hidden="true" tabindex="-1"></a>]  <span class="co"># Add your custom metric definitions</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Set the model configuration.</p>
<div id="cell-42" class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>model_config <span class="op">=</span> <span class="st">"falcon-7b"</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> model_config <span class="op">==</span> <span class="st">"falcon-7b"</span>:</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    model_params <span class="op">=</span> {</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">"max_context_width"</span>: <span class="dv">2048</span>,</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">"hidden_width"</span>: <span class="dv">4544</span>,</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">"num_layers"</span>: <span class="dv">32</span>,</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">"num_heads"</span>: <span class="dv">71</span>,</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">"num_heads_kv"</span>: <span class="dv">71</span>,</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">RuntimeError</span>(<span class="st">"Unknown model config"</span>)</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k, v <span class="kw">in</span> model_params.items():</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>    hyperparameters[k] <span class="op">=</span> v</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="specify-essential-parameters-for-a-sagemaker-training-job" class="level2">
<h2 class="anchored" data-anchor-id="specify-essential-parameters-for-a-sagemaker-training-job">Specify essential parameters for a SageMaker Training job</h2>
<p>Next, you use the <a href="https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html"><code>SageMaker Estimator class</code></a> to define a SageMaker Training Job, passing values through the following parameters for training job name, the number of EC2 instances, the instance type, and the size of the volume attached to the instances.</p>
<ul>
<li><code>instance_count</code></li>
<li><code>instance_type</code></li>
<li><code>volume_size</code></li>
<li><code>base_job_name</code></li>
</ul>
<section id="update-the-type-and-the-number-of-ec2-instance-to-use" class="level3">
<h3 class="anchored" data-anchor-id="update-the-type-and-the-number-of-ec2-instance-to-use">Update the type and the number of EC2 instance to use</h3>
<p>The instance type and the number of instances you specify to the <code>instance_type</code> and <code>instance_count</code> parameters, respectively, determine the total number of GPUs (world size).</p>
<p><span class="math display">\[ \text{(world size) = (the number of GPUs on a single instance)}\times\text{(the number of instances)}\]</span></p>
<div id="cell-44" class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>instance_type <span class="op">=</span> <span class="st">"ml.p4d.24xlarge"</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>instance_count <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="co"># set to the number of GPUs on that instance</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>processes_per_host <span class="op">=</span> <span class="dv">8</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To look up the number of GPUs of different instance types, see <a href="https://aws.amazon.com/ec2/instance-types/">Amazon EC2 Instance Types</a>. Use the section <strong>Accelerated Computing</strong> to see general purpose GPU instances. Note that, for example, a given instance type <code>p4d.24xlarge</code> has a corresponding instance type <code>ml.p4d.24xlarge</code> in SageMaker. For SageMaker supported <code>ml</code> instances and cost information, see <a href="https://aws.amazon.com/sagemaker/pricing/">Amazon SageMaker Pricing</a>.</p>
</section>
<section id="specify-a-base-job-name" class="level3">
<h3 class="anchored" data-anchor-id="specify-a-base-job-name">Specify a base job name</h3>
<div id="cell-47" class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>machine_str <span class="op">=</span> instance_type.split(<span class="st">"."</span>)[<span class="dv">1</span>] <span class="op">+</span> instance_type.split(<span class="st">"."</span>)[<span class="dv">2</span>][:<span class="dv">3</span>]</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>sharding_degree <span class="op">=</span> hyperparameters[<span class="st">"sharded_data_parallel_degree"</span>]</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>base_job_name <span class="op">=</span> (</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>    <span class="ss">f'smp-</span><span class="sc">{</span>model_config<span class="sc">}</span><span class="ss">-</span><span class="sc">{</span>machine_str<span class="sc">}</span><span class="ss">-sdp</span><span class="sc">{</span>sharding_degree<span class="sc">}</span><span class="ss">-bs</span><span class="sc">{</span>hyperparameters[<span class="st">"train_batch_size"</span>]<span class="sc">}</span><span class="ss">'</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-48" class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> use_fsx:</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># If you want to resume training, set checkpoint_s3_uri to the same path as a previous job.</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Previous checkpoint to load must have same model config.</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    checkpoint_bucket <span class="op">=</span> <span class="ss">f"s3://sagemaker-</span><span class="sc">{</span>region<span class="sc">}</span><span class="ss">-</span><span class="sc">{</span>account<span class="sc">}</span><span class="ss">/"</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    checkpoint_s3_uri <span class="op">=</span> (</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"</span><span class="sc">{</span>checkpoint_bucket<span class="sc">}</span><span class="ss">/experiments/gpt_synthetic_simpletrainer_checkpoints/</span><span class="sc">{</span>base_job_name<span class="sc">}</span><span class="ss">/"</span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-49" class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"base_job_name: </span><span class="sc">{</span>base_job_name<span class="sc">}</span><span class="ss"> checkpoint_s3_uri: </span><span class="sc">{</span>checkpoint_s3_uri<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="create-a-sagemaker-pytorch-estimator" class="level3">
<h3 class="anchored" data-anchor-id="create-a-sagemaker-pytorch-estimator">Create a SageMaker PyTorch estimator</h3>
<p>The following cell constructs a PyTorch estimator using the parameters defined above. To see how the SageMaker APIs and functions are applied to the script, see the <code>train.py</code> file.</p>
<div id="cell-51" class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>kwargs <span class="op">=</span> {}</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> use_fsx:</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Use the security group and subnet that was used to create the fsx filesystem</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>    kwargs[<span class="st">"security_group_ids"</span>] <span class="op">=</span> [fsx_security_group_id]</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    kwargs[<span class="st">"subnets"</span>] <span class="op">=</span> [fsx_subnet]</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>smp_estimator <span class="op">=</span> PyTorch(</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>    entry_point<span class="op">=</span><span class="st">"train.py"</span>,</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>    source_dir<span class="op">=</span>os.getcwd(),</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>    role<span class="op">=</span>role,</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>    instance_type<span class="op">=</span>instance_type,</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>    instance_count<span class="op">=</span>instance_count,</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>    sagemaker_session<span class="op">=</span>sagemaker_session,</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>    distribution<span class="op">=</span>{</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">"mpi"</span>: {</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>            <span class="st">"enabled"</span>: <span class="va">True</span>,</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>            <span class="st">"processes_per_host"</span>: processes_per_host,</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>            <span class="st">"custom_mpi_options"</span>: mpioptions,</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">"smdistributed"</span>: {</span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>            <span class="st">"modelparallel"</span>: {</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>                <span class="st">"enabled"</span>: <span class="va">True</span>,</span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>                <span class="st">"parameters"</span>: {</span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"ddp"</span>: <span class="va">True</span>,</span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"skip_tracing"</span>: <span class="va">True</span>,</span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"delayed_parameter_initialization"</span>: hyperparameters[<span class="st">"delayed_param"</span>] <span class="op">&gt;</span> <span class="dv">0</span>,</span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"offload_activations"</span>: hyperparameters[<span class="st">"offload_activations"</span>] <span class="op">&gt;</span> <span class="dv">0</span>,</span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"activation_loading_horizon"</span>: hyperparameters[<span class="st">"activation_loading_horizon"</span>],</span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"sharded_data_parallel_degree"</span>: hyperparameters[<span class="st">"sharded_data_parallel_degree"</span>],</span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"fp16"</span>: hyperparameters[<span class="st">"fp16"</span>] <span class="op">&gt;</span> <span class="dv">0</span>,</span>
<span id="cb30-31"><a href="#cb30-31" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"bf16"</span>: hyperparameters[<span class="st">"bf16"</span>] <span class="op">&gt;</span> <span class="dv">0</span>,</span>
<span id="cb30-32"><a href="#cb30-32" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># partitions is a required param in the current SM SDK so it needs to be passed,</span></span>
<span id="cb30-33"><a href="#cb30-33" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"partitions"</span>: <span class="dv">1</span>,</span>
<span id="cb30-34"><a href="#cb30-34" aria-hidden="true" tabindex="-1"></a>                },</span>
<span id="cb30-35"><a href="#cb30-35" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb30-36"><a href="#cb30-36" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb30-37"><a href="#cb30-37" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb30-38"><a href="#cb30-38" aria-hidden="true" tabindex="-1"></a>    framework_version<span class="op">=</span><span class="st">"2.0"</span>,</span>
<span id="cb30-39"><a href="#cb30-39" aria-hidden="true" tabindex="-1"></a>    py_version<span class="op">=</span><span class="st">"py310"</span>,</span>
<span id="cb30-40"><a href="#cb30-40" aria-hidden="true" tabindex="-1"></a>    output_path<span class="op">=</span>s3_output_bucket,</span>
<span id="cb30-41"><a href="#cb30-41" aria-hidden="true" tabindex="-1"></a>    checkpoint_s3_uri<span class="op">=</span>checkpoint_s3_uri <span class="cf">if</span> <span class="kw">not</span> use_fsx <span class="cf">else</span> <span class="va">None</span>,</span>
<span id="cb30-42"><a href="#cb30-42" aria-hidden="true" tabindex="-1"></a>    checkpoint_local_path<span class="op">=</span>hyperparameters[<span class="st">"checkpoint-dir"</span>] <span class="cf">if</span> use_fsx <span class="cf">else</span> <span class="va">None</span>,</span>
<span id="cb30-43"><a href="#cb30-43" aria-hidden="true" tabindex="-1"></a>    metric_definitions<span class="op">=</span>metric_definitions,</span>
<span id="cb30-44"><a href="#cb30-44" aria-hidden="true" tabindex="-1"></a>    hyperparameters<span class="op">=</span>hyperparameters,</span>
<span id="cb30-45"><a href="#cb30-45" aria-hidden="true" tabindex="-1"></a>    debugger_hook_config<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb30-46"><a href="#cb30-46" aria-hidden="true" tabindex="-1"></a>    disable_profiler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb30-47"><a href="#cb30-47" aria-hidden="true" tabindex="-1"></a>    base_job_name<span class="op">=</span>base_job_name,</span>
<span id="cb30-48"><a href="#cb30-48" aria-hidden="true" tabindex="-1"></a>    <span class="op">**</span>kwargs,</span>
<span id="cb30-49"><a href="#cb30-49" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Finally, run the <code>estimator.fit</code> method to launch the SageMaker training job of the Falcon model with sharded data parallelism.</p>
<div id="cell-53" class="cell" data-scrolled="true">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>smp_estimator.fit(inputs<span class="op">=</span>data_channels, logs<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="accessing-the-training-logs" class="level2">
<h2 class="anchored" data-anchor-id="accessing-the-training-logs">Accessing the Training Logs</h2>
<p>You can access the training logs from <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/WhatIsCloudWatch.html">Amazon CloudWatch</a>. Make sure to look at the logs of <strong>algo-1</strong> because that is the main node whose output stream has the training job logs.</p>
<p>You can use CloudWatch to track SageMaker GPU and memory utilization during training and inference. To view the metrics and logs that SageMaker writes to CloudWatch, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/monitoring-cloudwatch.html#cloudwatch-metrics-jobs">SageMaker Jobs and Endpoint Metrics</a> in the Amazon SageMaker Developer Guide.</p>
<p>If you are a new user of CloudWatch, see <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/GettingStarted.html">Getting Started with Amazon CloudWatch</a>.</p>
<p>For additional information on monitoring and analyzing Amazon SageMaker training jobs, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/training-metrics.html">Monitor and Analyze Training Jobs Using Metrics</a>.</p>
</section>
<section id="deploying-trained-model-for-inference" class="level2">
<h2 class="anchored" data-anchor-id="deploying-trained-model-for-inference">Deploying Trained Model for Inference</h2>
<p>In most cases, a trained model can be deployed on a single device for inference because inference only requires a small amount of memory. You can use the SMP API to create a single, unified model after training: the <a href="https://sagemaker.readthedocs.io/en/stable/api/training/smp_versions/latest/smd_model_parallel_tensorflow.html#smp.DistributedModel.save_model">smp.DistributedModel.save_model()</a> method for TensorFlow, and the <a href="https://sagemaker.readthedocs.io/en/stable/api/training/smp_versions/latest/smd_model_parallel_pytorch.html#apis-for-saving-and-loading">smp.save()</a> function for PyTorch.</p>
<p>After you build and train your models, you can deploy them to get predictions in one of two ways:</p>
<ul>
<li>To set up a persistent endpoint to get predictions from your models, use SageMaker hosting services. For an overview on deploying a single model or multiple models with SageMaker hosting services, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-deployment.html#how-it-works-hosting">Deploy a Model on SageMaker Hosting Services</a>.</li>
<li>To get predictions for an entire dataset, use SageMaker batch transform. For an overview on deploying a model with SageMaker Batch Transform, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html">Get Inferences for an Entire Dataset with Batch Transform</a>.</li>
</ul>
<p>To learn more about deploying models for inference using SageMaker, see <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html">Deploy Models for Inference</a>.</p>
</section>
<section id="notebook-ci-test-results" class="level2">
<h2 class="anchored" data-anchor-id="notebook-ci-test-results">Notebook CI Test Results</h2>
<p>This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-1/training%7Cdistributed_training%7Cpytorch%7Cmodel_parallel%7Cgpt2%7Csmp-train-gpt-simple-sharded-data-parallel.ipynb" class="img-fluid figure-img"></p>
<figcaption>This badge failed to load. Check your device’s internet connectivity, otherwise the service is currently unavailable</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-2/training%7Cdistributed_training%7Cpytorch%7Cmodel_parallel%7Cgpt2%7Csmp-train-gpt-simple-sharded-data-parallel.ipynb" class="img-fluid figure-img"></p>
<figcaption>This badge failed to load. Check your device’s internet connectivity, otherwise the service is currently unavailable</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-1/training%7Cdistributed_training%7Cpytorch%7Cmodel_parallel%7Cgpt2%7Csmp-train-gpt-simple-sharded-data-parallel.ipynb" class="img-fluid figure-img"></p>
<figcaption>This badge failed to load. Check your device’s internet connectivity, otherwise the service is currently unavailable</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ca-central-1/training%7Cdistributed_training%7Cpytorch%7Cmodel_parallel%7Cgpt2%7Csmp-train-gpt-simple-sharded-data-parallel.ipynb" class="img-fluid figure-img"></p>
<figcaption>This badge failed to load. Check your device’s internet connectivity, otherwise the service is currently unavailable</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/sa-east-1/training%7Cdistributed_training%7Cpytorch%7Cmodel_parallel%7Cgpt2%7Csmp-train-gpt-simple-sharded-data-parallel.ipynb" class="img-fluid figure-img"></p>
<figcaption>This badge failed to load. Check your device’s internet connectivity, otherwise the service is currently unavailable</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-1/training%7Cdistributed_training%7Cpytorch%7Cmodel_parallel%7Cgpt2%7Csmp-train-gpt-simple-sharded-data-parallel.ipynb" class="img-fluid figure-img"></p>
<figcaption>This badge failed to load. Check your device’s internet connectivity, otherwise the service is currently unavailable</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-2/training%7Cdistributed_training%7Cpytorch%7Cmodel_parallel%7Cgpt2%7Csmp-train-gpt-simple-sharded-data-parallel.ipynb" class="img-fluid figure-img"></p>
<figcaption>This badge failed to load. Check your device’s internet connectivity, otherwise the service is currently unavailable</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-3/training%7Cdistributed_training%7Cpytorch%7Cmodel_parallel%7Cgpt2%7Csmp-train-gpt-simple-sharded-data-parallel.ipynb" class="img-fluid figure-img"></p>
<figcaption>This badge failed to load. Check your device’s internet connectivity, otherwise the service is currently unavailable</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-central-1/training%7Cdistributed_training%7Cpytorch%7Cmodel_parallel%7Cgpt2%7Csmp-train-gpt-simple-sharded-data-parallel.ipynb" class="img-fluid figure-img"></p>
<figcaption>This badge failed to load. Check your device’s internet connectivity, otherwise the service is currently unavailable</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-north-1/training%7Cdistributed_training%7Cpytorch%7Cmodel_parallel%7Cgpt2%7Csmp-train-gpt-simple-sharded-data-parallel.ipynb" class="img-fluid figure-img"></p>
<figcaption>This badge failed to load. Check your device’s internet connectivity, otherwise the service is currently unavailable</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-1/training%7Cdistributed_training%7Cpytorch%7Cmodel_parallel%7Cgpt2%7Csmp-train-gpt-simple-sharded-data-parallel.ipynb" class="img-fluid figure-img"></p>
<figcaption>This badge failed to load. Check your device’s internet connectivity, otherwise the service is currently unavailable</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-2/training%7Cdistributed_training%7Cpytorch%7Cmodel_parallel%7Cgpt2%7Csmp-train-gpt-simple-sharded-data-parallel.ipynb" class="img-fluid figure-img"></p>
<figcaption>This badge failed to load. Check your device’s internet connectivity, otherwise the service is currently unavailable</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-1/training%7Cdistributed_training%7Cpytorch%7Cmodel_parallel%7Cgpt2%7Csmp-train-gpt-simple-sharded-data-parallel.ipynb" class="img-fluid figure-img"></p>
<figcaption>This badge failed to load. Check your device’s internet connectivity, otherwise the service is currently unavailable</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-2/training%7Cdistributed_training%7Cpytorch%7Cmodel_parallel%7Cgpt2%7Csmp-train-gpt-simple-sharded-data-parallel.ipynb" class="img-fluid figure-img"></p>
<figcaption>This badge failed to load. Check your device’s internet connectivity, otherwise the service is currently unavailable</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-south-1/training%7Cdistributed_training%7Cpytorch%7Cmodel_parallel%7Cgpt2%7Csmp-train-gpt-simple-sharded-data-parallel.ipynb" class="img-fluid figure-img"></p>
<figcaption>This badge failed to load. Check your device’s internet connectivity, otherwise the service is currently unavailable</figcaption>
</figure>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/marcelcastrobr\.github\.io\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
<script>
  function loadGiscus() {
    // Function to get the theme based on body class
    const getTheme = () => {
      let baseTheme = document.getElementById('giscus-base-theme').value;
      let altTheme = document.getElementById('giscus-alt-theme').value;
      return document.body.classList.contains('quarto-dark') ? altTheme : baseTheme;
    };
    const script = document.createElement("script");
    script.src = "https://giscus.app/client.js";
    script.async = true;
    script.dataset.repo = "marcelcastrobr/marcelcastrobr.github.io";
    script.dataset.repoId = "R_kgDOIwFH3A";
    script.dataset.category = "General";
    script.dataset.categoryId = "DIC_kwDOIwFH3M4Cjnq1";
    script.dataset.mapping = "title";
    script.dataset.reactionsEnabled = "1";
    script.dataset.emitMetadata = "0";
    script.dataset.inputPosition = "top";
    script.dataset.theme = getTheme();
    script.dataset.lang = "en";
    script.crossOrigin = "anonymous";
    // Append the script to the desired div instead of at the end of the body
    document.getElementById("quarto-content").appendChild(script);
  }
  loadGiscus();
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Copyright 2023, Marcel Castro</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>