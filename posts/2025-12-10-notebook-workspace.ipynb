{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8a5e495c",
      "metadata": {},
      "source": [
        "---\n",
        "aliases:\n",
        "- /2025/12/10/notebookworkspace\n",
        "badges: true\n",
        "date:   2025-12-10 15:04:07 +0200\n",
        "date-modified: last-modified\n",
        "categories:\n",
        "- Snowflake\n",
        "- Notebook\n",
        "- Snowflake Workspace\n",
        "description: Running Snowflake Notebooks in Workspace.\n",
        "output-file: 2025-12-10-notebook-in-workspace.html\n",
        "title: Snowflake Notebooks in Workspace\n",
        "toc: true\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "173d6391",
      "metadata": {},
      "source": [
        "# Snowflake Notebooks in Workspace\n",
        "\n",
        "DISCLAIMER: Snowflake Notebooks in Workspace is in [PuPr](https://docs.snowflake.com/en/release-notes/2025/other/2025-12-16-notebooks-in-workspaces) (Public Preview) at the time of writing this notebook (December 18, 2025). \n",
        "\n",
        "Snowflake Notebook is a fully-managed Jupyter-powered notebook built for end-to-end data science and machine learning development on Snowflake data. \n",
        "\n",
        "This includes: \n",
        "\n",
        "- Familiar Jupyter experience - Get the full power of a Jupyter Python notebook environment, directly connected to the governed Snowflake data. \n",
        "\n",
        "- Full IDE features: Easy editing and file management for maximum productivity.\n",
        "\n",
        "- Powerful for AI/ML: Runs in a pre-built container environment optimized for scalable AI/ML development with fully-managed access to CPUs and GPUs, parallel data loading, distributed training APIs for popular ML packages (e.g. xgboost, pytorch, lightGBM).\n",
        "\n",
        "- Governed collaboration: Enable multiple users to collaborate simultaneously with built-in governance and a complete history of changes via Git or shared workspaces.\n",
        "\n",
        "In Snowflake, a notebook consumes compute resources through its configured virtual warehouses or compute pools. \n",
        "\n",
        "In this blog we are focusing on **Snowflake Notebooks in Workspace on a compute pool**.\n",
        "\n",
        "\n",
        "![Snowflake Notebooks in Workspaces](./images/notebook-workspaces1.png)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c674a3c7",
      "metadata": {},
      "source": [
        "## Deep dive: Workspace, Service and Compute Pool\n",
        "\n",
        "\n",
        "Workspaces provides a unified editor for creating, organizing, and managing code across multiple file types that you can use to analyze data, develop models, and build pipelines.\n",
        "\n",
        "A workspace is private to you but can be [shared](https://docs.snowflake.com/en/user-guide/ui-snowsight/workspaces-shared) in order to allow collaboration. \n",
        "\n",
        "\n",
        "Snowflake Notebooks in workspace run on **Snowpark Container Services (SPCS)** and a [compute pool](https://docs.snowflake.com/en/developer-guide/snowpark-container-services/working-with-compute-pool) is required.\n",
        "\n",
        "When a user run a notebook, Snowflake creates a **notebook service** which host the notebook kernel. Upon creation of a notebook service, the users can configure python version, Snowflake container runtime version (e.g. with CPU or GPU), compute pool, idle timeout and external access integrations.\n",
        "\n",
        "As depicted in picture below, each notebook service is connected to a user and sits in a node on the selected compute pool. It is important to note that all notebooks connected to the same notebook service (e.g. SERVICE A in picture below) share the compute resources on that node. \n",
        "\n",
        "\n",
        "\n",
        "![SPCS Service Architecture](./images/notebook-compute-diagram1.png)\n",
        "\n",
        "\n",
        "### How it works\n",
        "\n",
        "\n",
        "Once the first notebook gets connected to a service on the compute pool, other notebooks can hook onto the same service instantly. \n",
        "Each service occupies one compute pool node. \n",
        "\n",
        "The notebooks on the same service will share the compute resource on the compute pool node. Here, each notebook still maintains its \n",
        "own virtual environment.\n",
        "\n",
        "#### Key things to consider:\n",
        "\n",
        "- **Idle time**: the Idle time is set on the container service. \n",
        "For example, if it is set to 4 hours, the container service automatically shuts down if all notebooks connected to it have stopped \n",
        "running for 4 hours.\n",
        "\n",
        "- **external access integration - EAI**: EAIs are managed on the container service which applies to all notebooks in the same Workspace. \n",
        "\n",
        "- **%lsmagic**: `%lsmagic` is supported.\n",
        "\n",
        "- **requirements.txt**: Specify package versions and ensure consistent environment setup by using `!pip install -r requirements.txt` \n",
        "Check versions [here](https://docs.snowflake.com/en/developer-guide/snowflake-ml/container-runtime-ml#snowflake-runtime-cpu-packages) to make sure\n",
        "your package version specified is compatible with the supported version range.\n",
        "\n",
        "- You can upload your wheel file by: `!pip install file_name.whl`\n",
        "\n",
        "\n",
        "#### Nice to know\n",
        "You can import packages from stages, with:\n",
        "\n",
        "```python\n",
        "from snowflake.snowpark import Session\n",
        "import sys\n",
        "session = Session.builder.getOrCreate()\n",
        "session.file.get(\"@stage_name/math_tools.py\",\"/tmp/\")\n",
        "sys.path.append(\"/tmp/\")\n",
        "import math_tools\n",
        "math_tools.add_one(3)\n",
        "```\n",
        "\n",
        "\n",
        "#### Limitations to consider (as per 2025-12-18):\n",
        "\n",
        "- `plotly`, `altair`, and other visualization packages that rely on HTML rendering are not yet supported.\n",
        "\n",
        "- Notebooks in different Workspaces cannot share the same service. \n",
        "\n",
        "- Artifact Repo and Custom Images are in the roadmap."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d150abc3-5507-4d06-be73-c2a70d4e773c",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false
      },
      "source": [
        "## Managing Snowflake Notebooks in Workspace\n",
        "\n",
        "Below you see some considerations to take while using Snowflake Notebooks in Workspace, which include cost and monitoring capability.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04fa5d79-ae87-4e4b-b103-b03c5801d42d",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false
      },
      "source": [
        "### Cost Aspects\n",
        "A notebook consumes compute resources through its configured virtual warehouses or compute pools. \n",
        "To manage costs and ensure efficient operations, itâ€™s important to monitor usage across individual notebooks, users, \n",
        "and the underlying compute infrastructure. This visibility helps ensure efficient operations and supports cost accountability \n",
        "throughout your environment.\n",
        "\n",
        "Snowflake provides access to detailed usage data through ACCOUNT_USAGE views and system tables. This data can help answer questions such as:\n",
        "\n",
        "- What is the hourly credit consumption per notebook?\n",
        "- How frequently were notebooks run in the past week?\n",
        "- Which users ran notebooks in the past month?\n",
        "- Which compute pools or warehouses did notebooks use over the past week?\n",
        "- What is the total credit cost of notebooks using a specific compute resource?\n",
        "\n",
        "For a broader overview of compute-related cost management, see [Exploring compute cost](https://docs.snowflake.com/en/user-guide/cost-exploring-compute).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3d12803-9e91-4210-8795-3dcf349afa70",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false
      },
      "source": [
        "#### Query: Cost to run a specific notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "208a95dd-0995-435f-8028-38de707badff",
      "metadata": {
        "language": "sql",
        "name": "monitor_cost",
        "resultVariableName": "dataframe_2",
        "title": "monitor_cost",
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "SELECT\n",
        "  notebook_name,\n",
        "  SUM(credits) AS total_credits\n",
        "FROM snowflake.account_usage.notebooks_container_runtime_history\n",
        "WHERE start_time >= DATEADD(day, -30, CURRENT_TIMESTAMP())\n",
        "GROUP BY notebook_name\n",
        "ORDER BY total_credits DESC;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dd5d19b-d1a7-4fc5-89ff-e44008898358",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false
      },
      "source": [
        "#### Query: Total compute pool cost per notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11086c39-38ab-4009-a963-d7623f7ef201",
      "metadata": {
        "language": "sql",
        "resultVariableName": "dataframe_4",
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "SELECT\n",
        "  notebook_name,\n",
        "  compute_pool_name,\n",
        "  SUM(credits) AS total_credits\n",
        "FROM snowflake.account_usage.notebooks_container_runtime_history\n",
        "--WHERE compute_pool_name = '<example_cp_name>'\n",
        "GROUP BY notebook_name, compute_pool_name\n",
        "ORDER BY total_credits DESC;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "007eb637-d640-4ab7-b19b-121559ae9f54",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false
      },
      "source": [
        "#### Query: Identify users who ran a specific notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6099260e-34ea-44e4-82db-2847c3948641",
      "metadata": {
        "language": "sql",
        "name": "user_notebook",
        "resultVariableName": "dataframe_6",
        "title": "user_notebook",
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "SELECT\n",
        "  DISTINCT user_name,\n",
        "  SUM(credits) AS total_credits\n",
        "FROM snowflake.account_usage.notebooks_container_runtime_history\n",
        "--WHERE notebook_name = '<example_nb_name>';\n",
        "GROUP BY user_name\n",
        "ORDER BY total_credits DESC;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2c277ea-0aca-4646-a262-a9b2045a41ce",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "from snowflake.snowpark.context import get_active_session\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "session = get_active_session()\n",
        "\n",
        "# Query the data\n",
        "query = \"\"\"\n",
        "SELECT\n",
        "  user_name,\n",
        "  SUM(credits) AS total_credits\n",
        "FROM snowflake.account_usage.notebooks_container_runtime_history\n",
        "GROUP BY user_name\n",
        "ORDER BY total_credits DESC\n",
        "\"\"\"\n",
        "\n",
        "df = session.sql(query).to_pandas()\n",
        "\n",
        "# Create bar chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(df['USER_NAME'], df['TOTAL_CREDITS'])\n",
        "plt.xlabel('User')\n",
        "plt.ylabel('Total Credits')\n",
        "plt.title('Total Credits by User')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2348072b",
      "metadata": {},
      "source": [
        "## Compute Pool Concept\n",
        "\n",
        "A compute pool is an account-level construct, analogous to a Snowflake virtual warehouse. \n",
        "The naming scope of the compute pool is your account.\n",
        "That is, you cannot have multiple compute pools with the same name in your account.\n",
        "\n",
        "The minimum information required to create a compute pool includes the following:\n",
        "\n",
        "- The machine type (referred to as the instance family) to provision for the compute pool nodes\n",
        "- The minimum nodes to launch the compute pool with\n",
        "- The maximum number of nodes the compute pool can scale to (Snowflake manages the scaling.)\n",
        "\n",
        "\n",
        "By default, all workloads can run on a compute pool, such as:\n",
        "\n",
        "- user-deployed:  **services** and jobs\n",
        "- workloads managed by Snowflake: **notebooks**, model serving, and ML jobs.\n",
        "\n",
        "You can control which workloads run on those compute pools by using account-level parameters: Check ALLOWED_SPCS_WORKLOAD_TYPES and DISALLOWED_SPCS_WORKLOAD_TYPES to manage \n",
        "the workloads that can run on a compute pool.\n",
        "\n",
        "Snowflake uses the placement group concept for fault isolation within Snowflake region. Check [Compute Pool Placement](https://docs.snowflake.com/en/developer-guide/snowpark-container-services/working-with-compute-pool#compute-pool-placement)\n",
        " for more information, especially in cases where you would like to have low latency between nodes for tightly coupled services.\n",
        "\n",
        "\n",
        "Other important things to consider:\n",
        "\n",
        "- [compute pool privileges](https://docs.snowflake.com/en/developer-guide/snowpark-container-services/working-with-compute-pool#compute-pool-privileges)\n",
        "\n",
        "- [compute pool maintenance](https://docs.snowflake.com/en/developer-guide/snowpark-container-services/working-with-compute-pool#compute-pool-maintenance)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d7e34c8",
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "--SHOW COMPUTE POOLS;\n",
        "SHOW COMPUTE POOLS;\n",
        "SELECT \n",
        "  \"instance_family\",\n",
        "  \"state\",\n",
        "  COUNT(*) AS number_of_pools\n",
        "FROM TABLE(RESULT_SCAN(LAST_QUERY_ID()))\n",
        "GROUP BY \"state\", \"instance_family\"\n",
        "ORDER BY \"state\", number_of_pools DESC;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39344e0c",
      "metadata": {},
      "source": [
        "## Services Concept\n",
        "\n",
        "Snowpark Container Services lets you more easily deploy, manage, and scale containerized applications. \n",
        "After you create an application and upload the application image to a \n",
        "repository in your Snowflake account, you can run your application containers as a service.\n",
        "\n",
        "A **service** represents Snowflake running your containerized application on a compute pool, \n",
        "which is a collection of virtual machine (VM) nodes. \n",
        "\n",
        "There are two types of services:\n",
        "- Long-running services. A long-running service is like a web service that does not end automatically. \n",
        "After you create a service, Snowflake manages the running service. \n",
        "For example, if a service container stops, for whatever reason, Snowflake restarts that container so the service runs uninterrupted. (e.g. [CREATE SERVICE](https://docs.snowflake.com/en/sql-reference/sql/create-service) command)\n",
        "\n",
        "\n",
        "- Job services. A job service terminates when your code exits, similar to a stored procedure.\n",
        "When all containers exit, the job service is done. (e.g. [EXECUTE JOB SERVICE](https://docs.snowflake.com/en/sql-reference/sql/execute-job-service) command)\n",
        "\n",
        "See picture below for an illustration, or in [working with services](https://docs.snowflake.com/en/developer-guide/snowpark-container-services/working-with-services) for detailed info.\n",
        "\n",
        "![SPCS Service Architecture](./images/spcs-service.png)\n",
        "\n",
        "\n",
        "\n",
        "Important things to note:\n",
        "\n",
        "- While Snowflake might distribute instances of a service across multiple compute pool nodes, \n",
        "all containers within a single service instance always run on the same compute pool node.\n",
        "\n",
        "- You can create services via SQL, Snowflake Python APIs, Snowflake Rest APIs and also Snowflake CLI.\n",
        "\n",
        "- Make use of network policies for network ingress and external access integration for network egress.\n",
        "\n",
        "\n",
        "### Scenarios for using Snowpark Container Services\n",
        "\n",
        "Common workloads are:\n",
        "- Batch Data Processing Jobs: Jobs like stored procedures across multiple job instances, and graphics processing unit (GPU) for computationally intensive tasks like AI and machine learning.\n",
        "\n",
        "- Service Functions: See an example [here](https://docs.snowflake.com/en/developer-guide/snowpark-container-services/tutorials/tutorial-1).\n",
        "\n",
        "- APIs or Web UI Over Snowflake Data: Deploy services that expose APIs or web interfaces with embedded business logic. Users interact with the service rather than raw data. \n",
        "\n",
        "Check also some [additional considerations for services](https://docs.snowflake.com/en/developer-guide/snowpark-container-services/additional-considerations-services-jobs).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2c587c5",
      "metadata": {},
      "source": [
        "## **References:**\n",
        "\n",
        "- [Annoucement: Dec 16, 2025: Notebooks in Workspaces - Preview](https://docs.snowflake.com/en/release-notes/2025/other/2025-12-16-notebooks-in-workspaces)\n",
        "- [Snowflake Notebooks in Workspaces](https://docs.snowflake.com/en/user-guide/ui-snowsight/notebooks-in-workspaces/notebooks-in-workspaces-overview)\n",
        "- [Notebook usage and cost monitoring](https://docs.snowflake.com/en/user-guide/ui-snowsight/notebooks-usage#cost-monitoring-on-container-runtime)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
