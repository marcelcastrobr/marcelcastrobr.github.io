{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8a5e495c",
      "metadata": {},
      "source": [
        "---\n",
        "aliases:\n",
        "- /2025/12/10/notebookworkspace\n",
        "badges: true\n",
        "categories:\n",
        "- Snowflake\n",
        "- Notebook\n",
        "- Snowflake Workspace\n",
        "date: '2025-12-10'\n",
        "description: Running Snowflake Notebooks in Workspace.\n",
        "output-file: 2025-12-10-notebook-in-workspace.html\n",
        "title: Best Practices for Snowflake Notebooks in Workspace\n",
        "toc: true\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "173d6391",
      "metadata": {},
      "source": [
        "# Best Practices for Snowflake Notebooks in Workspace\n",
        "\n",
        "DISCLAIMER: Snowflake Notebooks in Workspace was in PrPr (Private Preview) at the time of writing this notebook (December 10, 2025). \n",
        "So you might expect some changes as the service is developed further and becomes PuPr (Public Preview) and GA (Generally Available).\n",
        "\n",
        "Snowflake Notebook is a fully-managed Jupyter-powered notebook built for end-to-end DS and ML development on Snowflake data. \n",
        "This includes: \n",
        "- Familiar Jupyter experience - Get the full power of a Jupyter Python notebook environment, directly connected to the governed Snowflake data. \n",
        "- Full IDE features: Easy editing and file management for maximum productivity.\n",
        "- Powerful for AI/ML: Runs in a pre-built container environment optimized for scalable AI/ML development with fully-managed access to CPUs and GPUs, parallel data loading, distributed training APIs for popular ML packages (e.g. xgboost, pytorch, lightGBM).\n",
        "- Governed collaboration: Enable multiple users to collaborate simultaneously with built-in governance and a complete history of changes via Git or shared workspaces.\n",
        "\n",
        "In Snowflake, a notebook consumes compute resources through its configured virtual warehouses or compute pools. \n",
        "In this blog we are focusing on Snowflake Notebooks in Workspace which run on Snowpark Container Services (SPCS) \n",
        "and a [compute pool](https://docs.snowflake.com/en/developer-guide/snowpark-container-services/working-with-compute-pool) is required.\n",
        "\n",
        "![SPCS Service Architecture](./images/spcs-service.png)\n",
        "\n",
        "\n",
        "\n",
        "References:\n",
        "-  [Notebook usage and cost monitoring](https://docs.snowflake.com/en/user-guide/ui-snowsight/notebooks-usage#cost-monitoring-on-container-runtime)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af2e73b2-563b-4135-b3fd-4d83491973b8",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false
      },
      "source": [
        "## Compute Pool: Concept\n",
        "\n",
        "A compute pool is an account-level construct, analogous to a Snowflake virtual warehouse. \n",
        "The naming scope of the compute pool is your account.\n",
        "That is, you cannot have multiple compute pools with the same name in your account.\n",
        "\n",
        "The minimum information required to create a compute pool includes the following:\n",
        "\n",
        "- The machine type (referred to as the instance family) to provision for the compute pool nodes\n",
        "- The minimum nodes to launch the compute pool with\n",
        "- The maximum number of nodes the compute pool can scale to (Snowflake manages the scaling.)\n",
        "\n",
        "\n",
        "By default, all workloads can run on a compute pool, such as: \n",
        "- user-deployed:  **services** and jobs\n",
        "- workloads managed by Snowflake: notebooks, model serving, and ML jobs.\n",
        "\n",
        "You can control which workloads run on those compute pools by using account-level parameters: Check ALLOWED_SPCS_WORKLOAD_TYPES and DISALLOWED_SPCS_WORKLOAD_TYPES to manage \n",
        "the workloads that can run on a compute pool.\n",
        "\n",
        "Snowflake uses the placement group concept for fault isolation within Snowflake region. Check [Compute Pool Placement](https://docs.snowflake.com/en/developer-guide/snowpark-container-services/working-with-compute-pool#compute-pool-placement)\n",
        " for more information, especially in cases where you would like to have low latency between nodes for tightly coupled services.\n",
        "\n",
        "\n",
        "Other important things to consider:\n",
        "- [compute pool privileges](https://docs.snowflake.com/en/developer-guide/snowpark-container-services/working-with-compute-pool#compute-pool-privileges)\n",
        "- [compute pool maintenance](https://docs.snowflake.com/en/developer-guide/snowpark-container-services/working-with-compute-pool#compute-pool-maintenance): In general, scheduled maintenance occurs every Saturday from 8 PM to Sunday at 8 AM, and every Sunday from 8 PM to Monday at 8 AM\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "688d2723-4cda-4a70-bba9-22a3e3a258b5",
      "metadata": {
        "language": "sql",
        "name": "show_computepools",
        "resultVariableName": "dataframe_7",
        "title": "show_computepools"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (3023944329.py, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    --SHOW COMPUTE POOLS;\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "--SHOW COMPUTE POOLS;\n",
        "SHOW COMPUTE POOLS;\n",
        "SELECT \n",
        "  \"instance_family\",\n",
        "  \"state\",\n",
        "  COUNT(*) AS number_of_pools\n",
        "FROM TABLE(RESULT_SCAN(LAST_QUERY_ID()))\n",
        "GROUP BY \"state\", \"instance_family\"\n",
        "ORDER BY \"state\", number_of_pools DESC;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78d845a8-51ba-41fc-ad15-3f770fe650d3",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false
      },
      "source": [
        "## Services: Concept\n",
        "\n",
        "Snowpark Container Services lets you more easily deploy, manage, and scale containerized applications. \n",
        "After you create an application and upload the application image to a \n",
        "repository in your Snowflake account, you can run your application containers as a service.\n",
        "\n",
        "A **service** represents Snowflake running your containerized application on a compute pool, \n",
        "which is a collection of virtual machine (VM) nodes. \n",
        "\n",
        "There are two types of services:\n",
        "- Long-running services. A long-running service is like a web service that does not end automatically. \n",
        "After you create a service, Snowflake manages the running service. \n",
        "For example, if a service container stops, for whatever reason, Snowflake restarts that container so the service runs uninterrupted. (e.g. [CREATE SERVICE](https://docs.snowflake.com/en/sql-reference/sql/create-service) command)\n",
        "- Job services. A job service terminates when your code exits, similar to a stored procedure.\n",
        "When all containers exit, the job service is done. (e.g. [EXECUTE JOB SERVICE](https://docs.snowflake.com/en/sql-reference/sql/execute-job-service) command)\n",
        "\n",
        "See picture below for an illustration, or in [working with services](https://docs.snowflake.com/en/developer-guide/snowpark-container-services/working-with-services) for detailed info.\n",
        "\n",
        "Important things to note:\n",
        "- While Snowflake might distribute instances of a service across multiple compute pool nodes, \n",
        "all containers within a single service instance always run on the same compute pool node.\n",
        "- You can create services via SQL, Snowflake Python APIs, Snowflake Rest APIs and also Snowflake CLI.\n",
        "- Make use of network policies for network ingress and external access integration for network egress.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab8d1721-88ea-437c-9ec1-33c7a95fabbf",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false
      },
      "source": [
        "### Scenarios for using Snowpark Container Services\n",
        "\n",
        "Common workloads are:\n",
        "- Batch Data Processing Jobs: Jobs like stored procedures across multiple job instances, and graphics processing unit (GPU) for computationally intensive tasks like AI and machine learning.\n",
        "\n",
        "- Service Functions: See an example [here](https://docs.snowflake.com/en/developer-guide/snowpark-container-services/tutorials/tutorial-1).\n",
        "\n",
        "- APIs or Web UI Over Snowflake Data: Deploy services that expose APIs or web interfaces with embedded business logic. Users interact with the service rather than raw data. \n",
        "\n",
        "Check also some [additional considerations for services](https://docs.snowflake.com/en/developer-guide/snowpark-container-services/additional-considerations-services-jobs)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3dbed37-7358-43bd-a6d3-377396608c4b",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false
      },
      "source": [
        "## Snowflake Notebooks in Workspace using Services: How it works\n",
        "\n",
        "Once the first notebook gets connected to a service on the compute pool, other notebooks can hook onto the same service instantly. \n",
        "Each service occupies one compute pool node. \n",
        "The notebooks on the same service will share the compute resource on the compute pool node. Here, each notebook still maintains its \n",
        "own virtual environment.\n",
        "\n",
        "### Key things to consider:\n",
        "\n",
        "- **Idle time**: the Idle time is set on the container service. \n",
        "For example, if it is set to 4 hours, the container service automatically shuts down if all notebooks connected to it have stopped \n",
        "running for 4 hours.\n",
        "- **external access integration - EAI**: EAIs are managed on the container service which applies to all notebooks in the same Workspace. \n",
        "- **%lsmagic**: `%lsmagic` is supported.\n",
        "- **requirements.txt**: Specify package versions and ensure consistent environment setup by using `!pip install -r requirements.txt` \n",
        "Check versions [here](https://docs.snowflake.com/en/developer-guide/snowflake-ml/container-runtime-ml#snowflake-runtime-cpu-packages) to make sure\n",
        "your package version specified is compatible with the supported version range.\n",
        "- You can upload your wheel file by: `!pip install file_name.whl`\n",
        "\n",
        "\n",
        "#### Nice to know\n",
        "You can import packages from stages, with:\n",
        "\n",
        "```python\n",
        "from snowflake.snowpark import Session\n",
        "import sys\n",
        "session = Session.builder.getOrCreate()\n",
        "session.file.get(\"@stage_name/math_tools.py\",\"/tmp/\")\n",
        "sys.path.append(\"/tmp/\")\n",
        "import math_tools\n",
        "math_tools.add_one(3)\n",
        "```\n",
        "\n",
        "\n",
        "#### Limitations to consider:\n",
        "- `plotly`, `altair`, and other visualization packages that rely on HTML rendering are not yet supported.\n",
        "- Notebooks in different Workspaces cannot share the same service. \n",
        "- Artifact Repo and Custom Images are in the roadmap.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08ebd156-6a31-44d1-86b8-0d680ecb69eb",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%lsmagic"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d150abc3-5507-4d06-be73-c2a70d4e773c",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false
      },
      "source": [
        "## Managing Snowflake Notebooks in Workspace\n",
        "\n",
        "Below you see some considerations to take while using Snowflake Notebooks in Workspace, which include cost and monitoring capability.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04fa5d79-ae87-4e4b-b103-b03c5801d42d",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false
      },
      "source": [
        "### Cost Aspects\n",
        "A notebook consumes compute resources through its configured virtual warehouses or compute pools. \n",
        "To manage costs and ensure efficient operations, itâ€™s important to monitor usage across individual notebooks, users, \n",
        "and the underlying compute infrastructure. This visibility helps ensure efficient operations and supports cost accountability \n",
        "throughout your environment.\n",
        "\n",
        "Snowflake provides access to detailed usage data through ACCOUNT_USAGE views and system tables. This data can help answer questions such as:\n",
        "\n",
        "- What is the hourly credit consumption per notebook?\n",
        "- How frequently were notebooks run in the past week?\n",
        "- Which users ran notebooks in the past month?\n",
        "- Which compute pools or warehouses did notebooks use over the past week?\n",
        "- What is the total credit cost of notebooks using a specific compute resource?\n",
        "\n",
        "For a broader overview of compute-related cost management, see [Exploring compute cost](https://docs.snowflake.com/en/user-guide/cost-exploring-compute).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3d12803-9e91-4210-8795-3dcf349afa70",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false
      },
      "source": [
        "#### Query: Cost to run a specific notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "208a95dd-0995-435f-8028-38de707badff",
      "metadata": {
        "language": "sql",
        "name": "monitor_cost",
        "resultVariableName": "dataframe_2",
        "title": "monitor_cost"
      },
      "outputs": [],
      "source": [
        "SELECT\n",
        "  notebook_name,\n",
        "  SUM(credits) AS total_credits\n",
        "FROM snowflake.account_usage.notebooks_container_runtime_history\n",
        "WHERE start_time >= DATEADD(day, -30, CURRENT_TIMESTAMP())\n",
        "GROUP BY notebook_name\n",
        "ORDER BY total_credits DESC;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dd5d19b-d1a7-4fc5-89ff-e44008898358",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false
      },
      "source": [
        "#### Query: Total compute pool cost per notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11086c39-38ab-4009-a963-d7623f7ef201",
      "metadata": {
        "language": "sql",
        "resultVariableName": "dataframe_4"
      },
      "outputs": [],
      "source": [
        "SELECT\n",
        "  notebook_name,\n",
        "  compute_pool_name,\n",
        "  SUM(credits) AS total_credits\n",
        "FROM snowflake.account_usage.notebooks_container_runtime_history\n",
        "--WHERE compute_pool_name = '<example_cp_name>'\n",
        "GROUP BY notebook_name, compute_pool_name\n",
        "ORDER BY total_credits DESC;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "007eb637-d640-4ab7-b19b-121559ae9f54",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false
      },
      "source": [
        "#### Query: Identify users who ran a specific notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6099260e-34ea-44e4-82db-2847c3948641",
      "metadata": {
        "language": "sql",
        "name": "user_notebook",
        "resultVariableName": "dataframe_6",
        "title": "user_notebook"
      },
      "outputs": [],
      "source": [
        "SELECT\n",
        "  DISTINCT user_name,\n",
        "  SUM(credits) AS total_credits\n",
        "FROM snowflake.account_usage.notebooks_container_runtime_history\n",
        "--WHERE notebook_name = '<example_nb_name>';\n",
        "GROUP BY user_name\n",
        "ORDER BY total_credits DESC;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d013156-0757-4c08-a755-a15b52aa837b",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "from snowflake.snowpark.context import get_active_session\n",
        "import plotly.express as px\n",
        "\n",
        "session = get_active_session()\n",
        "\n",
        "# Query the data\n",
        "query = \"\"\"\n",
        "SELECT\n",
        "  user_name,\n",
        "  SUM(credits) AS total_credits\n",
        "FROM snowflake.account_usage.notebooks_container_runtime_history\n",
        "GROUP BY user_name\n",
        "ORDER BY total_credits DESC\n",
        "\"\"\"\n",
        "\n",
        "df = session.sql(query).to_pandas()\n",
        "\n",
        "# Create bar chart\n",
        "fig = px.bar(df, \n",
        "             x='USER_NAME', \n",
        "             y='TOTAL_CREDITS',\n",
        "             title='Total Credits by User',\n",
        "             labels={'USER_NAME': 'User', 'TOTAL_CREDITS': 'Total Credits'})\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2c277ea-0aca-4646-a262-a9b2045a41ce",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "from snowflake.snowpark.context import get_active_session\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "session = get_active_session()\n",
        "\n",
        "# Query the data\n",
        "query = \"\"\"\n",
        "SELECT\n",
        "  user_name,\n",
        "  SUM(credits) AS total_credits\n",
        "FROM snowflake.account_usage.notebooks_container_runtime_history\n",
        "GROUP BY user_name\n",
        "ORDER BY total_credits DESC\n",
        "\"\"\"\n",
        "\n",
        "df = session.sql(query).to_pandas()\n",
        "\n",
        "# Create bar chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(df['USER_NAME'], df['TOTAL_CREDITS'])\n",
        "plt.xlabel('User')\n",
        "plt.ylabel('Total Credits')\n",
        "plt.title('Total Credits by User')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d056c1f2-444d-42c4-8200-5da43750e6ec",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
